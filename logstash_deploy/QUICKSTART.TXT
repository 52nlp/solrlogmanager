Quickstart 

1. Copy the deploy folder to your disk.

2. Copy provided ManagedIndexSchemaFactory configured logstash_logs directory to your Solr collection folder.  

3. In Solr Admin add a new core.  In the name and instanceDir fields enter: logstash_logs. Accept the defaults
   for the remaining fields and click on the 'Add Core' button.

4. Open lw_solr_conf in a text editor.  In the 'input' section of the config file add the path to your log file[s] by changing 
			path => [ "/logfilePath/**/./*" ]
			
   If your Solr instance is not running on the default localhost:8983 then change the collection_host and collection_port values in the 
   ouptut section of the config file.
   
   Note that the included LogStash config file uses the kv_filter to automatcially create named fields when it discovers
   name=value pattern in the scanned message.  This simple transform will work as is for many types of logs.  But it can get tripped up by  
   patterns 'a=b=c' for example which can result in invalid Solr field names.  Modify the filters in the config file as necessary to perform 
   LogStash transformations consistent with the data coming from your environment (for details on LogStash configuration see http://logstash.net/docs/1.2.2/).
   
5. Download LogStash to the deploy folder - https://download.elasticsearch.org/logstash/logstash/logstash-1.2.2-flatjar.jar

6. Execute LogStash: java -jar logstash-1.2.2-flatjar.jar agent -f lw_solr_conf -p .

Log data should be displaying in your shell window and it should be getting stored in Solr.

Happy Logging!